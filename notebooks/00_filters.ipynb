{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filters\n",
    "\n",
    "> Linear convolution filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from math import ceil, sqrt\n",
    "from typing import Callable\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian filter\n",
    "\n",
    "Implements filtering with a $k$-order Gaussian derivative as a series of 1D convolutions. Currently supports up to second-order derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def gaussian_filter(\n",
    "    img: torch.Tensor,  # The input tensor\n",
    "    sigma: float,  # Standard deviation for the Gaussian kernel\n",
    "    order: int | list = 0,  # The order of the filter's derivative along each dim\n",
    "    mode: str = \"reflect\",  # Padding mode for `torch.nn.functional.pad`\n",
    "    truncate: float = 4.0,  # Number of standard deviations to sample the filter\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Convolves an image with a Gaussian kernel (or its derivatives).\n",
    "\n",
    "    Inspired by the API of `scipy.ndimage.gaussian_filter` and the\n",
    "    implementation of `diplib.Gauss`.\n",
    "    \"\"\"\n",
    "\n",
    "    # Specify the dimensions of the convolution to use\n",
    "    ndim = img.ndim - 2\n",
    "    if isinstance(order, int):\n",
    "        order = [order] * ndim\n",
    "    else:\n",
    "        assert len(order) == ndim, \"Specify the Gaussian derivative order for each dim\"\n",
    "    convfn = getattr(F, f\"conv{ndim}d\")\n",
    "\n",
    "    # Convolve along the rows, columns, and depth (optional)\n",
    "    for dim, derivative_order in enumerate(order):\n",
    "        img = _conv(img, convfn, sigma, derivative_order, truncate, mode, dim)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _gaussian_kernel_1d(\n",
    "    sigma: float, order: int, truncate: float, dtype: torch.dtype, device: torch.device\n",
    ") -> torch.Tensor:\n",
    "    # Set the size of the kernel according to the sigma\n",
    "    radius = ceil(sigma * truncate)\n",
    "    x = torch.arange(-radius, radius + 1, dtype=dtype, device=device)\n",
    "\n",
    "    # Initialize the zeroth-order Gaussian kernel\n",
    "    var = sigma**2\n",
    "    g = (-x.pow(2) / (2 * var)).exp() / (sqrt(2 * torch.pi) * sigma)\n",
    "\n",
    "    # Optionally convert to a higher-order kernel\n",
    "    if order == 0:\n",
    "        return g\n",
    "    elif order == 1:\n",
    "        g1 = g * (-x / var)\n",
    "        g1 -= g1.mean()\n",
    "        g1 /= (g1 * x).sum() / -1  # Normalize the filter's impulse response to -1\n",
    "        return g1\n",
    "    elif order == 2:\n",
    "        g2 = g * (x.pow(2) / var - 1) / var\n",
    "        g2 -= g2.mean()\n",
    "        g2 /= (g2 * x.pow(2)).sum() / 2  # Normalize the filter's impulse response to 2\n",
    "        return g2\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Only supports order in [0, 1, 2], not {order}\")\n",
    "\n",
    "\n",
    "def _conv(\n",
    "    img: torch.Tensor,\n",
    "    convfn: Callable,\n",
    "    sigma: float,\n",
    "    order: int,\n",
    "    truncate: float,\n",
    "    mode: str,\n",
    "    dim: int,\n",
    "):\n",
    "    # Make a 1D kernel and pad such that the image size remains the same\n",
    "    kernel = _gaussian_kernel_1d(sigma, order, truncate, img.dtype, img.device)\n",
    "    padding = len(kernel) // 2\n",
    "\n",
    "    # Specify the padding dimensions\n",
    "    pad = [0] * 2 * (img.ndim - 2)\n",
    "    for idx in range(2 * dim, 2 * dim + 2):\n",
    "        pad[idx] = padding\n",
    "    pad = pad[::-1]\n",
    "    x = F.pad(img, pad, mode=mode)\n",
    "\n",
    "    # Specify the dimension along which to do the convolution\n",
    "    view = [1] * img.ndim\n",
    "    view[dim + 2] *= -1\n",
    "\n",
    "    return convfn(x, weight=kernel.view(*view))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hessian matrix of an image\n",
    "\n",
    "Compute a symmetric matrix of all second-order partial Gaussian derivatives of an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from diptorch.linalg import eigvalsh2, eigvalsh3\n",
    "\n",
    "\n",
    "def hessian(\n",
    "    img: torch.Tensor, sigma: float, as_matrix: bool = False, **kwargs\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute the Hessian of a 2D or 3D image.\"\"\"\n",
    "    if img.ndim == 4:\n",
    "        hessian = _hessian_2d(img, sigma, **kwargs)\n",
    "    elif img.ndim == 5:\n",
    "        hessian = _hessian_3d(img, sigma, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"img can only be 2D or 3D, not {img.ndim-2}D\")\n",
    "\n",
    "    if as_matrix:\n",
    "        return _hessian_as_matrix(*hessian)\n",
    "    else:\n",
    "        return hessian\n",
    "\n",
    "\n",
    "def hessian_eigenvalues(img: torch.Tensor, sigma: float, **kwargs):\n",
    "    H = hessian(img, sigma, **kwargs)\n",
    "    if len(H) == 3:\n",
    "        eig = eigvalsh2(*H)\n",
    "    elif len(H) == 6:\n",
    "        eig = eigvalsh3(*H)\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized number of upper triangular elements: {len(H)}\")\n",
    "\n",
    "    # Sort the eigenvalues such that |lambda[1]| <= ... <= |lambda[n]|\n",
    "    return torch.take_along_dim(eig, eig.abs().argsort(dim=1), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _hessian_2d(img: torch.Tensor, sigma: float, **kwargs):\n",
    "    xx = gaussian_filter(img, sigma, order=[0, 2], **kwargs)\n",
    "    yy = gaussian_filter(img, sigma, order=[2, 0], **kwargs)\n",
    "    xy = gaussian_filter(img, sigma, order=[1, 1], **kwargs)\n",
    "    return xx, xy, yy\n",
    "\n",
    "\n",
    "def _hessian_3d(\n",
    "    img: torch.Tensor, sigma: float, truncate: float = 4.0, mode: str = \"reflect\"\n",
    "):\n",
    "    # Precompute 1D kernels for the zeroth, first, and second derivatives\n",
    "    g0 = _gaussian_kernel_1d(sigma, 0, truncate, img.dtype, img.device)\n",
    "    g1 = _gaussian_kernel_1d(sigma, 1, truncate, img.dtype, img.device)\n",
    "    g2 = _gaussian_kernel_1d(sigma, 2, truncate, img.dtype, img.device)\n",
    "    padding = len(g0) // 2\n",
    "\n",
    "    # Fuse individual kernels into a multi-channel 1D kernel\n",
    "    kx = torch.concat(\n",
    "        [\n",
    "            g2.view(1, 1, 1, 1, -1),\n",
    "            g1.view(1, 1, 1, 1, -1),\n",
    "            g1.view(1, 1, 1, 1, -1),\n",
    "            g0.view(1, 1, 1, 1, -1),\n",
    "            g0.view(1, 1, 1, 1, -1),\n",
    "            g0.view(1, 1, 1, 1, -1),\n",
    "        ],\n",
    "        dim=0,\n",
    "    )\n",
    "    ky = torch.concat(\n",
    "        [\n",
    "            g0.view(1, 1, 1, -1, 1),\n",
    "            g1.view(1, 1, 1, -1, 1),\n",
    "            g0.view(1, 1, 1, -1, 1),\n",
    "            g2.view(1, 1, 1, -1, 1),\n",
    "            g1.view(1, 1, 1, -1, 1),\n",
    "            g0.view(1, 1, 1, -1, 1),\n",
    "        ],\n",
    "        dim=0,\n",
    "    )\n",
    "    kz = torch.concat(\n",
    "        [\n",
    "            g0.view(1, 1, -1, 1, 1),\n",
    "            g0.view(1, 1, -1, 1, 1),\n",
    "            g1.view(1, 1, -1, 1, 1),\n",
    "            g0.view(1, 1, -1, 1, 1),\n",
    "            g1.view(1, 1, -1, 1, 1),\n",
    "            g2.view(1, 1, -1, 1, 1),\n",
    "        ],\n",
    "        dim=0,\n",
    "    )\n",
    "\n",
    "    # Run vectorized convolutions over each dimension\n",
    "    x = img.expand(-1, 6, -1, -1, -1)\n",
    "    x = F.conv3d(x, weight=kx, padding=(padding, 0, 0), groups=6)\n",
    "    x = F.conv3d(x, weight=ky, padding=(0, padding, 0), groups=6)\n",
    "    x = F.conv3d(x, weight=kz, padding=(0, 0, padding), groups=6)\n",
    "\n",
    "    return x.split(1, 1)\n",
    "\n",
    "\n",
    "def _hessian_as_matrix(*args):\n",
    "    if len(args) == 3:\n",
    "        xx, xy, yy = args\n",
    "        return torch.stack(\n",
    "            [\n",
    "                torch.concat([xx, xy], dim=1),\n",
    "                torch.concat([xy, yy], dim=1),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "    elif len(args) == 6:\n",
    "        xx, xy, xz, yy, yz, zz = args\n",
    "        return torch.stack(\n",
    "            [\n",
    "                torch.concat([xx, xy, xz], dim=1),\n",
    "                torch.concat([xy, yy, yz], dim=1),\n",
    "                torch.concat([xz, yz, zz], dim=1),\n",
    "            ],\n",
    "            dim=1,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid number of arguments: {len(args)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frangi\n",
    "\n",
    "Implements the Frangi filter for enhancing tubular structures in 2D and 3D images. Refer to the original paper: [Frangi et al., 1998](https://doi.org/10.1007/BFb0056195)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def frangi(\n",
    "    image: torch.Tensor,  # the intput image\n",
    "    sigma_range: tuple = (1, 10),  # the range of sigmas to use\n",
    "    scale_step: int = 2,  # the step between sigmas\n",
    "    sigmas: list = None,  # optional list of sigmas to use\n",
    "    alpha: float = 0.5,  # plate-like and line-like structures threshold\n",
    "    beta: float = 0.5,  # blob-like structures threshold\n",
    "    gamma: float = None,  # second order structure threshold\n",
    "    eps: float = 1e-10,\n",
    "    device: str | torch.device = None,\n",
    ") -> torch.tensor:\n",
    "\n",
    "    # torch.backends.cudnn.enabled = False # more memory intensive but faster\n",
    "    if image.ndim not in (4, 5):\n",
    "        raise ValueError(\n",
    "            f\"input image must be 2D or 3D with shape [B C H W] or [B C D H W], received shape: {image.shape}\",\n",
    "            \n",
    "        )\n",
    "\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # converting the input to float32 and moving it to the device\n",
    "    alpha = torch.tensor(alpha, dtype=torch.float32, device=device)\n",
    "    beta = torch.tensor(beta, dtype=torch.float32, device=device)\n",
    "    eps = torch.tensor(eps, dtype=torch.float32, device=device)\n",
    "    image = image.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    # if sigmas is not provided, generate them\n",
    "    if isinstance(sigmas, list):\n",
    "        sigmas = torch.tensor(sigmas, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        sigmas = torch.arange(\n",
    "            sigma_range[0],\n",
    "            sigma_range[1],\n",
    "            scale_step,\n",
    "            dtype=torch.float32,\n",
    "            device=device,\n",
    "        )\n",
    "    if torch.any(sigmas < 0.0):\n",
    "        raise ValueError(\"Sigma values must be positive\")\n",
    "\n",
    "    filtered_max = torch.zeros_like(image, dtype=torch.float32, device=device)\n",
    "\n",
    "    for sigma in sigmas:\n",
    "        eigenvalues = hessian_eigenvalues(image, sigma).squeeze()\n",
    "        eigenvalues = torch.take_along_dim(eigenvalues, abs(eigenvalues).argsort(0), 0)\n",
    "        lambda1 = eigenvalues[0]\n",
    "\n",
    "        if image.ndim == 4:\n",
    "            (lambda2,) = torch.maximum(eigenvalues[1:], eps)\n",
    "            lambda2 = lambda2\n",
    "            r_a = torch.inf\n",
    "            r_b = torch.abs(lambda1 / lambda2)  # eq 15\n",
    "            r_b = torch.nan_to_num(r_b, nan=0.0)\n",
    "\n",
    "        elif image.ndim == 5:\n",
    "            lambda2, lambda3 = torch.maximum(eigenvalues[1:], eps)\n",
    "            r_a = lambda2 / lambda3  # eq 11\n",
    "            r_b = abs(lambda1) / torch.sqrt(lambda2 * lambda3)  # eq 10\n",
    "\n",
    "        eigenvalues = torch.sqrt((eigenvalues**2).sum(dim=0))  # eq 12\n",
    "        if gamma is None:\n",
    "            gamma_t = eigenvalues.max() / 2\n",
    "            if gamma_t == 0:\n",
    "                gamma_t = 1\n",
    "        else:\n",
    "            gamma_t = gamma\n",
    "        result = 1.0 - torch.exp(-(r_a**2) / (2 * alpha**2))\n",
    "        result = result * (torch.exp(-(r_b**2) / (2 * beta**2 + eps)))\n",
    "        result = result * (1.0 - torch.exp(-(eigenvalues**2) / (2 * gamma_t**2 + eps)))\n",
    "\n",
    "        filtered_max = torch.maximum(filtered_max, result)\n",
    "\n",
    "    return filtered_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
